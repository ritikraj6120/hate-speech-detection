[INFO] (utils) Arguments:
[INFO] (utils)   batch_size: 512
[INFO] (utils)   command: train.py -d ../data/SemEval_task5/df_train.csv --trial ../data/SemEval_task5/df_test.csv -s ../data/sentiment_datasets/train_E6oV3lV.csv --word_list ../data/word_list/word_all.txt --emb ../glove.6B.300d.txt -o output_dir -b 512 --epochs 15 --lr 0.002 --maxlen 50 -t HHMM_transformer
[INFO] (utils)   data_path: ../data/SemEval_task5/df_train.csv
[INFO] (utils)   dropout_prob: 0.1
[INFO] (utils)   emb_dim: 300
[INFO] (utils)   emb_path: ../glove.6B.300d.txt
[INFO] (utils)   epochs: 15
[INFO] (utils)   humor_data_path: None
[INFO] (utils)   learn_rate: 0.002
[INFO] (utils)   loss: ce
[INFO] (utils)   maxlen: 50
[INFO] (utils)   model_type: HHMM_transformer
[INFO] (utils)   non_gate: False
[INFO] (utils)   out_dir_path: output_dir
[INFO] (utils)   sarcasm_data_path: None
[INFO] (utils)   sentiment_data_path: ../data/sentiment_datasets/train_E6oV3lV.csv
[INFO] (utils)   trial_data_path: ../data/SemEval_task5/df_test.csv
[INFO] (utils)   vocab_path: None
[INFO] (utils)   word_list_path: ../data/word_list/word_all.txt
[INFO] (utils)   word_norm: 1
[INFO] (data_reader) Creating vocabulary.........
[INFO] (data_reader)   185893 total words, 17537 unique words
[INFO] (data_reader)   Vocab size: 17537
